This project implements a Multilayer Perceptron (MLP) and its structured variations for optical-digit classification. 
  
Train your MLPs on the “optdig- its train.txt” data, tune the number of hidden units using the “optdigits valid.txt” data, and test the prediction performance using the “optdigits test.txt” data.  
  
#### Problem a)  
Implement a MLP with 1 hidden layer using the sigmoid activation func- tion S(x) = 1/(1+exp(-x)) for classifying the 10 digits (read the algorithm in Figure
 1+e
11.11 and section 11.7.3). Try MLPs with {2, 4, 6, 8, 10, 12, 14, 16, 18, 20}
hidden units. Report and plot the training and validation error rates by the number of hidden units. How many hidden units should you use? Report the error rate on the test set using this number of hidden units.  
  
#### Problem b)  
Train your MLP with 2 hidden units and visualize the data by the values of the hidden units (similar to Figure 11.18). Make a plot for the training, validation, and test sets separately.  
  
#### Problem c)  
Repeat previous question by training 3 hidden units and do the visualiza- tion using 3-D plot.  
